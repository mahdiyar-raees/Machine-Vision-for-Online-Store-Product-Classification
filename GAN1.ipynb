{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnRPJxH5q7dX"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB3lcsVBrAGN"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "18CwwwD0iZL9"
      },
      "outputs": [],
      "source": [
        "import numpy             as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow        as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f7qayM0VbH1b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLhwU_fFrBw_"
      },
      "source": [
        "Importing Drive and unzipinig the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO7VBLHjlgKw",
        "outputId": "f3013bb9-ab4c-47a0-8bc8-34f5efc89b57"
      },
      "outputs": [],
      "source": [
        "#  from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# REAL DATA SET\n",
        "#!wget https://data.mendeley.com/public-files/datasets/rscbjbr9sj/files/5699a1d8-d1b6-45db-bb92-b61051445347/file_downloaded\n",
        "\n",
        "\n",
        "# SECOND DATA SET\n",
        "#!wget https://drive.google.com/uc?id=1rPo3ZCc83BROZoxSzVDyYzgkJOfgL02U&export=download\n",
        "#!unzip drive/MyDrive/Eye/EyeD\n",
        "# !unzip drive/MyDrive/EyeD\n",
        "#!tar xvzf drive/MyDrive/Eye/file_downloaded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeXrldqDrFP1"
      },
      "source": [
        "Determining the batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UVeXFBxV2dgY"
      },
      "outputs": [],
      "source": [
        "batch_size = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1LWSp4FrJTV"
      },
      "source": [
        "Defining the data generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FCWQSeFMN8OG"
      },
      "outputs": [],
      "source": [
        "\n",
        "c1_data_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale            = 1./255,\n",
        "    rotation_range     = 8,\n",
        "    width_shift_range  = 0.1,\n",
        "    height_shift_range = 0.1\n",
        ")\n",
        "\n",
        "c2_data_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale            = 1./255,\n",
        "    rotation_range     = 8,\n",
        "    width_shift_range  = 0.1,\n",
        "    height_shift_range = 0.1\n",
        ")\n",
        "\n",
        "c3_data_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale            = 1./255,\n",
        "    rotation_range     = 8,\n",
        "    width_shift_range  = 0.1,\n",
        "    height_shift_range = 0.1\n",
        ")\n",
        "c4_data_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale            = 1./255,\n",
        "    rotation_range     = 8,\n",
        "    width_shift_range  = 0.1,\n",
        "    height_shift_range = 0.1\n",
        ")\n",
        "c5_data_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale            = 1./255,\n",
        "    rotation_range     = 8,\n",
        "    width_shift_range  = 0.1,\n",
        "    height_shift_range = 0.1\n",
        ")\n",
        "c6_data_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale            = 1./255,\n",
        "    rotation_range     = 8,\n",
        "    width_shift_range  = 0.1,\n",
        "    height_shift_range = 0.1\n",
        ")\n",
        "c7_data_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale            = 1./255,\n",
        "    rotation_range     = 8,\n",
        "    width_shift_range  = 0.1,\n",
        "    height_shift_range = 0.1\n",
        ")\n",
        "c8_data_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale            = 1./255,\n",
        "    rotation_range     = 8,\n",
        "    width_shift_range  = 0.1,\n",
        "    height_shift_range = 0.1\n",
        ")\n",
        "c9_data_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale            = 1./255,\n",
        "    rotation_range     = 8,\n",
        "    width_shift_range  = 0.1,\n",
        "    height_shift_range = 0.1\n",
        ")\n",
        "c10_data_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale            = 1./255,\n",
        "    rotation_range     = 8,\n",
        "    width_shift_range  = 0.1,\n",
        "    height_shift_range = 0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXkiZhhPmgIt",
        "outputId": "2568815b-c628-407c-a521-ade433cecb04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 798 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "c1_data = c1_data_datagen.flow_from_directory(\n",
        "    'D:\\data_scienc_quera\\project2\\p1',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=None,\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "c2_data = c2_data_datagen.flow_from_directory(\n",
        "    'D:\\data_scienc_quera\\project2\\p2',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=None,\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 797 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "c3_data = c3_data_datagen.flow_from_directory(\n",
        "    'D:\\data_scienc_quera\\project2\\p3',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=None,\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 798 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "c4_data = c4_data_datagen.flow_from_directory(\n",
        "    'D:\\data_scienc_quera\\project2\\p4',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=None,\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "c5_data = c5_data_datagen.flow_from_directory(\n",
        "    'D:\\data_scienc_quera\\project2\\p5',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=None,\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "c6_data = c6_data_datagen.flow_from_directory(\n",
        "    'D:\\data_scienc_quera\\project2\\p6',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=None,\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "c7_data = c7_data_datagen.flow_from_directory(\n",
        "    'D:\\data_scienc_quera\\project2\\p7',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=None,\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "c8_data = c8_data_datagen.flow_from_directory(\n",
        "    'D:\\data_scienc_quera\\project2\\p8',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=None,\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "c9_data = c9_data_datagen.flow_from_directory(\n",
        "    'D:\\data_scienc_quera\\project2\\p9',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=None,\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 797 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "c10_data = c10_data_datagen.flow_from_directory(\n",
        "    'D:\\data_scienc_quera\\project2\\p10',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=None,\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcbHEMHgsCB2",
        "outputId": "9236a155-64cc-478f-cbec-675563a888c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale            = 1./255\n",
        ")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    'D:\\data_scienc_quera\\project2test',\n",
        "    target_size = (256,256),\n",
        "    batch_size  = batch_size ,\n",
        "    color_mode  = \"grayscale\",\n",
        "    class_mode  = \"categorical\",\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtEWTAZ8rO11"
      },
      "source": [
        "#Building the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qbajy4oUrQxF"
      },
      "source": [
        "Defining the Custom Activation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CSIqIWclK6of"
      },
      "outputs": [],
      "source": [
        "# custom activation function\n",
        "def custom_activation(output):\n",
        "  logexpsum = tf.keras.backend.sum(tf.keras.backend.exp(output), axis=-1, keepdims=True)\n",
        "  result    = logexpsum / (logexpsum + 1.0)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSLC5QUIrWDl"
      },
      "source": [
        "Defining Discriminator and the Classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "b58ozpcQPr8N"
      },
      "outputs": [],
      "source": [
        "def define_discriminator(in_shape=(256,256,1), n_classes=10):\n",
        "  in_image = tf.keras.layers.Input(shape=in_shape)\n",
        "\n",
        "  fe = tf.keras.layers.Conv2D(128, (3,3), strides = (1,1), padding = \"same\")(in_image)\n",
        "  fe = tf.keras.layers.MaxPool2D(pool_size = (2,2) , strides = (2,2))(fe)\n",
        "  fe = tf.keras.layers.LeakyReLU(alpha=0.2)(fe)\n",
        "\n",
        "  fe = tf.keras.layers.Dropout(0.7)(fe)\n",
        "\n",
        "  fe = tf.keras.layers.Conv2D(128, (3,3), strides = (1,1), padding = \"same\")(fe)\n",
        "  fe = tf.keras.layers.MaxPool2D(pool_size = (2,2) , strides = (2,2))(fe)\n",
        "  fe = tf.keras.layers.LeakyReLU(alpha=0.2)(fe)\n",
        "\n",
        "  fe = tf.keras.layers.Dropout(0.7)(fe)\n",
        "\n",
        "  fe = tf.keras.layers.Conv2D(128, (3,3), strides = (1,1), padding = \"same\")(fe)\n",
        "  fe = tf.keras.layers.MaxPool2D(pool_size = (2,2) , strides = (2,2))(fe)\n",
        "  fe = tf.keras.layers.LeakyReLU(alpha=0.2)(fe)\n",
        "\n",
        "  fe = tf.keras.layers.Dropout(0.7)(fe)\n",
        "\n",
        "  fe = tf.keras.layers.Conv2D(128, (3,3), strides = (1,1), padding = \"same\")(fe)\n",
        "  fe = tf.keras.layers.MaxPool2D(pool_size = (2,2) , strides = (2,2))(fe)\n",
        "  fe = tf.keras.layers.LeakyReLU(alpha=0.2)(fe)\n",
        "\n",
        "  fe = tf.keras.layers.Flatten()(fe)\n",
        "  fe = tf.keras.layers.Dropout(0.4)(fe)\n",
        "  fe = tf.keras.layers.Dense(n_classes)(fe)\n",
        "\n",
        "  c_out_layer = tf.keras.layers.Activation(\"softmax\")(fe)\n",
        "  c_model     = tf.keras.models.Model(in_image, c_out_layer)\n",
        "  c_model.compile(loss = \"categorical_crossentropy\", optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0002,  beta_1 = 0.5), metrics = [\"accuracy\"])\n",
        "  c_model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=tf.keras.optimizers.schedules.ExponentialDecay(0.0002, decay_steps=1000, decay_rate=0.1, staircase=True), beta_1=0.5), metrics=[\"accuracy\"])\n",
        "  d_out_layer = tf.keras.layers.Lambda(custom_activation)(fe)\n",
        "  d_model     = tf.keras.models.Model(in_image, d_out_layer)\n",
        "  d_model.compile(loss = \"binary_crossentropy\", optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0002, beta_1 = 0.5))\n",
        "  return d_model, c_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG3-zIv4raL8"
      },
      "source": [
        "Defining the Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Q90Wyufvkd_E"
      },
      "outputs": [],
      "source": [
        "def define_generator(latent_dim):\n",
        "  in_lat  = tf.keras.layers.Input(shape=(latent_dim,))\n",
        "  n_nodes = 128 * 8 * 8\n",
        "\n",
        "  gen = tf.keras.layers.Dense(n_nodes)(in_lat)\n",
        "  gen = tf.keras.layers.LeakyReLU(alpha = 0.2)(gen)\n",
        "  gen = tf.keras.layers.Reshape((8, 8, 128))(gen)\n",
        "\n",
        "  gen = tf.keras.layers.Conv2DTranspose(128, (4,4), strides = (2,2), padding = \"same\")(gen)\n",
        "  gen = tf.keras.layers.LeakyReLU(alpha = 0.2)(gen)\n",
        "\n",
        "  gen = tf.keras.layers.Conv2DTranspose(128, (4,4), strides = (2,2), padding = \"same\")(gen)\n",
        "  gen = tf.keras.layers.LeakyReLU(alpha = 0.2)(gen)\n",
        "\n",
        "  gen = tf.keras.layers.Conv2DTranspose(128, (4,4), strides = (2,2), padding = \"same\")(gen)\n",
        "  gen = tf.keras.layers.LeakyReLU(alpha = 0.2)(gen)\n",
        "\n",
        "  gen = tf.keras.layers.Conv2DTranspose(128, (4,4), strides = (2,2), padding = \"same\")(gen)\n",
        "  gen = tf.keras.layers.LeakyReLU(alpha = 0.2)(gen)\n",
        "\n",
        "  gen = tf.keras.layers.Conv2DTranspose(128, (4,4), strides = (2,2), padding = \"same\")(gen)\n",
        "  gen = tf.keras.layers.LeakyReLU(alpha = 0.2)(gen)\n",
        "\n",
        "  out_layer = tf.keras.layers.Conv2D(1, (7,7), activation = \"relu\", padding = \"same\")(gen)\n",
        "\n",
        "  model = tf.keras.models.Model(in_lat, out_layer)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW9M4kbJrcwL"
      },
      "source": [
        "Defining GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "m6yJSvbklsEz"
      },
      "outputs": [],
      "source": [
        "def define_gan(g_model, d_model):\n",
        "  d_model.trainable = False\n",
        "\n",
        "  gan_output = d_model(g_model.output)\n",
        "  model      = tf.keras.models.Model(g_model.input, gan_output)\n",
        "  opt        = tf.keras.optimizers.Adam(learning_rate = 0.0002, beta_1 = 0.5)\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=opt)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkMhhjXrrevk"
      },
      "source": [
        "How to generate real samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "muSdgXoMlxPt"
      },
      "outputs": [],
      "source": [
        "def generate_real_samples():\n",
        "  c1_Normal  = c1_data.next()\n",
        "  c1_Normaly  = np.array([1,0,0,0,0,0,0,0,0,0] * c1_Normal.shape[0]).reshape(c1_Normal.shape[0], -1)\n",
        "\n",
        "  c2_Normal  = c2_data.next()\n",
        "  c2_Normaly  = np.array([0,1,0,0,0,0,0,0,0,0] * c2_Normal.shape[0]).reshape(c2_Normal.shape[0], -1)\n",
        "\n",
        "  c3_Normal  = c3_data.next()\n",
        "  c3_Normaly  = np.array([0,0,1,0,0,0,0,0,0,0] * c3_Normal.shape[0]).reshape(c3_Normal.shape[0], -1)\n",
        "\n",
        "  c4_Normal  = c4_data.next()\n",
        "  c4_Normaly  = np.array([0,0,0,1,0,0,0,0,0,0] * c4_Normal.shape[0]).reshape(c4_Normal.shape[0], -1)\n",
        "\n",
        "  c5_Normal  = c5_data.next()\n",
        "  c5_Normaly  = np.array([0,0,0,0,1,0,0,0,0,0] * c5_Normal.shape[0]).reshape(c5_Normal.shape[0], -1)\n",
        "\n",
        "  c6_Normal  = c6_data.next()\n",
        "  c6_Normaly  = np.array([0,0,0,0,0,1,0,0,0,0] * c6_Normal.shape[0]).reshape(c6_Normal.shape[0], -1)\n",
        "\n",
        "\n",
        "  c7_Normal  = c7_data.next()\n",
        "  c7_Normaly  = np.array([0,0,0,0,0,0,1,0,0,0] * c7_Normal.shape[0]).reshape(c7_Normal.shape[0], -1)\n",
        "\n",
        "  c8_Normal  = c8_data.next()\n",
        "  c8_Normaly  = np.array([0,0,0,0,0,0,0,1,0,0] * c8_Normal.shape[0]).reshape(c8_Normal.shape[0], -1)\n",
        "\n",
        "  c9_Normal  = c9_data.next()\n",
        "  c9_Normaly  = np.array([0,0,0,0,0,0,0,0,1,0] * c9_Normal.shape[0]).reshape(c9_Normal.shape[0], -1)\n",
        "  \n",
        "  c10_Normal  = c10_data.next()\n",
        "  c10_Normaly  = np.array([0,0,0,0,0,0,0,0,0,1] * c10_Normal.shape[0]).reshape(c10_Normal.shape[0], -1)\n",
        "    \n",
        "\n",
        "  \n",
        "  X       = np.concatenate([ c1_Normal, c2_Normal, c3_Normal,c4_Normal, c5_Normal, c6_Normal,c7_Normal, c8_Normal, c9_Normal,c10_Normal])\n",
        "  labels  = np.concatenate([c1_Normaly, c2_Normaly, c3_Normaly,c4_Normaly, c5_Normaly, c6_Normaly,c7_Normaly, c8_Normaly, c9_Normaly,c10_Normaly])\n",
        "  y       = np.ones((X.shape[0], 1))\n",
        "\n",
        "  return [X, labels], y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW5VYGoCrhK1"
      },
      "source": [
        "How to generate fake samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ox7_mbT-mRtw"
      },
      "outputs": [],
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "  z_input = np.random.randn(latent_dim * n_samples)\n",
        "  z_input = z_input.reshape(n_samples, latent_dim)\n",
        "  return z_input\n",
        "\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "  z_input = generate_latent_points(latent_dim, n_samples)\n",
        "  images  = generator.predict(z_input)\n",
        "  y       = np.zeros((n_samples, 1))\n",
        "  return images, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWKf7AhCrn21"
      },
      "source": [
        "#Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LPAqTq3rpnU"
      },
      "source": [
        "Defining the train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fQQuZO6PmbS-"
      },
      "outputs": [],
      "source": [
        "def train(g_model, d_model, c_model, gan_model, latent_dim, n_epochs , batch_size):\n",
        "  bat_per_epo = int(9990 / (10 * batch_size))\n",
        "\n",
        "  for i in range(bat_per_epo * n_epochs):\n",
        "    [Xsup_real, ysup_real], y_real = generate_real_samples()\n",
        "    c_loss, c_acc                  = c_model.train_on_batch(Xsup_real, ysup_real)\n",
        "\n",
        "    d_loss1        = d_model.train_on_batch(Xsup_real, y_real)\n",
        "    X_fake, y_fake = generate_fake_samples(g_model, latent_dim, 10 * batch_size)\n",
        "    d_loss2        = d_model.train_on_batch(X_fake, y_fake)\n",
        "\n",
        "    X_gan, y_gan = generate_latent_points(latent_dim, 10* batch_size), np.ones((10 * batch_size, 1))\n",
        "    g_loss       = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\n",
        "    print(\">%d, c[%.3f,%.0f], d[%.3f,%.3f], g[%.3f]\" % (i+1, c_loss, c_acc*100, d_loss1, d_loss2, g_loss))\n",
        "\n",
        "  return c_model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAWp3f49rrvc"
      },
      "source": [
        "Defining the models and latent dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "eJyA8UI-Ik9f"
      },
      "outputs": [],
      "source": [
        "latent_dim = 100\n",
        "\n",
        "d_model, c_model = define_discriminator()\n",
        "g_model          = define_generator(latent_dim)\n",
        "gan_model        = define_gan(g_model, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eEoaZPZruPk"
      },
      "source": [
        "Loading model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsNY2nTGrw_t"
      },
      "source": [
        "Training the model and saving the Accuracy and Loss of test data in history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsOOnp1Y6tvp",
        "outputId": "5601d7f5-a175-4c0f-b165-23d23de886e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            ">1, c[2.560,30], d[0.157,2.407], g[0.095]\n",
            "1/1 [==============================] - 1s 1s/step\n",
            ">2, c[2.929,10], d[0.002,2.404], g[0.095]\n",
            "1/1 [==============================] - 1s 1s/step\n",
            ">3, c[2.504,0], d[0.002,2.398], g[0.095]\n",
            "1/1 [==============================] - 1s 1s/step\n",
            ">4, c[2.473,10], d[0.001,2.396], g[0.096]\n",
            "1/1 [==============================] - 1s 1s/step\n",
            ">5, c[2.645,20], d[0.001,2.395], g[0.096]\n",
            "1/1 [==============================] - 1s 1s/step\n",
            ">6, c[2.704,20], d[0.001,2.394], g[0.096]\n",
            "1/1 [==============================] - 1s 1s/step\n",
            ">7, c[2.413,20], d[0.001,2.393], g[0.096]\n",
            "1/1 [==============================] - 1s 1s/step\n",
            ">8, c[2.883,10], d[0.001,2.391], g[0.096]\n",
            "1/1 [==============================] - 1s 1s/step\n",
            ">9, c[2.539,0], d[0.001,2.389], g[0.096]\n",
            "1/1 [==============================] - 1s 1s/step\n",
            ">10, c[2.259,20], d[0.001,2.386], g[0.097]\n",
            "1/1 [==============================] - 1s 1s/step\n",
            ">11, c[2.562,10], d[0.001,2.382], g[0.097]\n",
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train(g_model, d_model, c_model, gan_model, latent_dim, n_epochs \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, batch_size \u001b[39m=\u001b[39;49m batch_size)\n",
            "Cell \u001b[1;32mIn[23], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(g_model, d_model, c_model, gan_model, latent_dim, n_epochs, batch_size)\u001b[0m\n\u001b[0;32m     10\u001b[0m   d_loss2        \u001b[39m=\u001b[39m d_model\u001b[39m.\u001b[39mtrain_on_batch(X_fake, y_fake)\n\u001b[0;32m     12\u001b[0m   X_gan, y_gan \u001b[39m=\u001b[39m generate_latent_points(latent_dim, \u001b[39m10\u001b[39m\u001b[39m*\u001b[39m batch_size), np\u001b[39m.\u001b[39mones((\u001b[39m10\u001b[39m \u001b[39m*\u001b[39m batch_size, \u001b[39m1\u001b[39m))\n\u001b[1;32m---> 13\u001b[0m   g_loss       \u001b[39m=\u001b[39m gan_model\u001b[39m.\u001b[39;49mtrain_on_batch(X_gan, y_gan)\n\u001b[0;32m     15\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m>\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, c[\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m%.0f\u001b[39;00m\u001b[39m], d[\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m], g[\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, c_loss, c_acc\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m, d_loss1, d_loss2, g_loss))\n\u001b[0;32m     17\u001b[0m \u001b[39mreturn\u001b[39;00m c_model\u001b[39m.\u001b[39mevaluate(test_data)\n",
            "File \u001b[1;32mc:\\Users\\COMPUTER SHAHR\\anaconda3\\envs\\quera1\\lib\\site-packages\\keras\\engine\\training.py:2381\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2377\u001b[0m     iterator \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39msingle_batch_iterator(\n\u001b[0;32m   2378\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[0;32m   2379\u001b[0m     )\n\u001b[0;32m   2380\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_train_function()\n\u001b[1;32m-> 2381\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   2383\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2384\u001b[0m \u001b[39mif\u001b[39;00m return_dict:\n",
            "File \u001b[1;32mc:\\Users\\COMPUTER SHAHR\\anaconda3\\envs\\quera1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\COMPUTER SHAHR\\anaconda3\\envs\\quera1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\COMPUTER SHAHR\\anaconda3\\envs\\quera1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\COMPUTER SHAHR\\anaconda3\\envs\\quera1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[1;32mc:\\Users\\COMPUTER SHAHR\\anaconda3\\envs\\quera1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\COMPUTER SHAHR\\anaconda3\\envs\\quera1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[1;32mc:\\Users\\COMPUTER SHAHR\\anaconda3\\envs\\quera1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(g_model, d_model, c_model, gan_model, latent_dim, n_epochs = 1, batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljg6P_Ylq0ZG"
      },
      "source": [
        "Evaluting C-Model on the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcQV92BS8vwp",
        "outputId": "da117b45-e361-4fb0-ef11-b14eb44bb886"
      },
      "outputs": [],
      "source": [
        "c_model.evaluate(c1_validation_data,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BbWkl0FqpBO"
      },
      "source": [
        "Saving Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDd6vdnndozM"
      },
      "outputs": [],
      "source": [
        "!mkdir -p saved_model/d_model/w\n",
        "!mkdir -p saved_model/c_model/w\n",
        "!mkdir -p saved_model/g_model/w\n",
        "\n",
        "d_model.save_weights('/content/drive/MyDrive/GAN_weights/saved_model/c_model/w')\n",
        "c_model.save_weights('/content/drive/MyDrive/GAN_weights/saved_model/d_model/w')\n",
        "g_model.save_weights('/content/drive/MyDrive/GAN_weights/saved_model/g_model/w')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weB4R0vNqkZP"
      },
      "source": [
        "# Testing Generative Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "yp66LcyDJGuV",
        "outputId": "1d9f7c41-35c0-49bf-84c9-3e4e3d956efb"
      },
      "outputs": [],
      "source": [
        "fake = g_model.predict(generate_latent_points(100, 2))\n",
        "plt.imshow(fake[0,:,:,0], cmap= \"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5pXS5wrsAMN"
      },
      "outputs": [],
      "source": [
        "#y_pred = c_model.predict(test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfVKrQ90I171"
      },
      "outputs": [],
      "source": [
        "predicted_categories = tf.argmax(y_pred, axis=1)\n",
        "true=[]\n",
        "predicted=[]\n",
        "for index , (image,label) in enumerate(test_data):\n",
        "  if index== 750:\n",
        "    break\n",
        "  true.append(label)\n",
        "  predicted.append(c_model.predict(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cdexUtoM5aw",
        "outputId": "ccd27f31-c084-48d1-8083-39b69a63b45c"
      },
      "outputs": [],
      "source": [
        "predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBx5s69NKB0V"
      },
      "outputs": [],
      "source": [
        "\n",
        "#true_categories = tf.concat(z[0:750], axis=0)\n",
        "predicted_categories = tf.argmax(predicted, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws9ysOGQKES1"
      },
      "outputs": [],
      "source": [
        "true_cat= []\n",
        "for item in true:\n",
        "  true_cat.append(np.argmax(item))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVAk6PDbbtIR",
        "outputId": "818b22a2-b46e-4ff8-b9a6-2b932ebe319d"
      },
      "outputs": [],
      "source": [
        "predicted_cat= []\n",
        "for item in predicted:\n",
        "  predicted_cat.append(np.argmax(item))\n",
        "confusion_matrix(predicted_cat, true_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KQ62aYVbyfZ",
        "outputId": "a9b95edb-f60e-4a51-b382-741da519a1b9"
      },
      "outputs": [],
      "source": [
        "true_cat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ShFjwP2JRF1",
        "outputId": "69a656a2-0272-4cc9-db1a-f0c831f94f9f"
      },
      "outputs": [],
      "source": [
        "predicted_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pjoJm90KstU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
